# HH preprocessing pipeline

Проект реализует пайплайн предобработки датасета HeadHunter
с использованием паттерна проектирования «Цепочка ответственности».

## Запуск

```bash
python app path/to/hh.csv
```

В директории с входным файлом будут созданы:
- `x_data.npy` — матрица признаков
- `y_data.npy` — целевая переменная (зарплата)

## Структура проекта

- `hh_preprocess/handlers` — обработчики цепочки
- `hh_preprocess/context.py` — контекст пайплайна
- `hh_preprocess/pipeline.py` — сборка цепочки
- `app` — CLI-точка входа
## Линейная регрессия и ML-моделирование

В рамках второй части задачи реализован модуль обучения моделей (Training) и применения их для прогнозирования зарплаты (Inference).

### Особенности предобработки (Feature Engineering)
Для улучшения качества линейных моделей были внедрены продвинутые методы генерации признаков:
- **NLP Embeddings:** Использование легковесной языковой модели `rubert-tiny2` (через `sentence-transformers`) для векторизации текста опыта работы.
- **Regex Skill Mining:** Извлечение ключевых навыков (Python, 1C, Management, Sales и др.) с учетом русской морфологии и корней слов.
- **Полиномиальные признаки:** Добавление нелинейных зависимостей (квадраты возраста и опыта).

### Реализованные модели
Проект поддерживает обучение и сравнение следующих алгоритмов:
1. **Модели линейной регрессии:** Linear Regression, Ridge (L2), Lasso (L1), ElasticNet.
2. **Ансамбли:** Random Forest, XGBoost (Gradient Boosting).

Для моделей реализован автоматический подбор гиперпараметров через `GridSearchCV`. Лучшая модель автоматически сохраняется для инференса.

### Сравнение моделей (Результаты экспериментов)

В таблице ниже приведены результаты работы моделей на тестовой выборке (Test Set).

| Модель | R² Score | RMSE (руб.) | MAE (руб.) |
| :--- | :--- | :--- | :--- |
| **XGBoost** | **0.6206** | **24 149** | **18 346** |
| Random Forest | 0.5628 | 26 907 | 19 815 |
| ElasticNet | 0.5827 | 26 379 | 19 742 |
| Ridge (L2) | 0.5825 | 26 384 | 19 748 |
| Lasso (L1) | 0.5824 | 26 388 | 19 751 |
| Linear Regression | 0.5823 | 26 390 | 19 754 |

> **Вывод:** XGBoost ожидаемо превзошел линейные модели, снизив ошибку (RMSE) более чем на 2000 рублей. Среди линейных моделей лучшей оказалась ElasticNet.

### Новые скрипты и запуск

#### 1. Обучение моделей (`train.py`)
Загружает обработанные данные, обучает все модели, сравнивает метрики (R2, RMSE) и сохраняет артефакты.

```bash
python train.py .
```
Результаты сохраняются в папку resources/:

**best_model.pkl** — сериализованная лучшая модель.

**metrics.json** — отчет по метрикам всех моделей.

#### 2. Инференс (inference.py)
Загружает лучшую модель и делает предсказание для новых данных.

```bash
python inference.py x_data.npy
```
Возвращает список предсказанных зарплат (в рублях).